# ----------------------------------------------------------------------------------------
#
#   Jupyterlab setup with NVIDIA GPU support
#
#   Jupyter Lab - http://localhost:8888
#   Tensorboard - http://localhost:6006
#   Obsidian    - http://localhost:3000
#   Mermaid     - http://localhost:9080
#
#   You must uncomment obsidian & mermaid services to enable them
#
# ----------------------------------------------------------------------------------------

services:

  # run jupyterlab on a local port 8888
  jupyterlab:
    container_name: lab-gpu
    hostname: lab-gpu
    image: stellars/stellars-jupyterlab-ds:latest
    build:
      context: build
      dockerfile: Dockerfile
    command: /start-jupyterlab.sh
    environment:
      - CONDA_DEFAULT_ENV=base # choices are: base, tensorflow, torch
      - GPU_SUPPORT_ENABLED=1 # system support for gpu
      - JUPYTERLAB_SERVER_IP=*
      - JUPYTERLAB_SERVER_TOKEN=
      - TF_CPP_MIN_LOG_LEVEL=3 # reduce tensorflow logging level
      - CUDA_VISIBLE_DEVICES=  # put 0,1,2 and other identifiers of gpu-s visible to CUDA
    ports:
      - 8888:8888 # jupyterlab
      - 8000:8000 # jupyterhub
      - 8001:8001 # jupyterhub proxy
      - 6006:6006 # tensorboard
      - 5000:5000 # mlflow
      - 3030:3030 # general purpose port for callbacks
    networks:
      - frontend
    volumes:
      - home:/home                    # jupyterlab user directory persistence
      - workspace:/home/lab/workspace # user projects workspace volume persistence
      - certs:/mnt/certs              # persistent certificate store for ssl
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]


  # obsidian notebook for managing markdown documentation
  #obsidian:
  #  image: lscr.io/linuxserver/obsidian:latest
  #  container_name: obsidian
  #  environment:
  #    - PUID=1000
  #    - PGID=1000
  #  volumes:
  #    - obsidian:/config
  #    - workspace:/config/workspace
  #  ports:
  #    - 3000:3000
  #    - 3001:3001
  #  networks:
  #    - frontend
  #  shm_size: "1gb"

  # mermaid online diagramming
  #mermaid:
  #  image: ghcr.io/mermaid-js/mermaid-live-editor
  #  container_name: mermaid
  #  ports:
  #    - 9080:8080
  #  networks:
  #    - frontend


volumes:
  workspace:
  certs:
  home:
  #obsidian:

networks:
  frontend:
    driver: bridge


# EOF

